---
title: "Getting-Started"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting-Started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(bayesian.gtheory)
```

Welcome to the world of Bayesian G-Theory! The `bayesian.gtheory` package is a user-created resource for executing G- and D-studies from Generalizability Theory through a Bayesian framework. It contains highly customizable functions for every possible one- and two-facet random study design to test the reliability of your data of interest. This vignette will walk the user through the general `bayesian.gtheory` workflow and prepare the user to try out the package for themselves. Thanks for checking out `bayesian.gtheory`!

## Background

### Generalizability Theory

For those unfamiliar, Generalizability Theory (G-Theory) is a powerful, modern statistical framework for quantifying reliability of measurement. It extends classical test theory by using an analysis of variance (ANOVA) model to separate observed score variance into independent variance components attributable to each ‚Äúfacet‚Äù of the study (i.e. rater, occasion, trial, etc.), their respective interactions, and the residual error. Furthermore, it excels in its ability to handle complex study designs, such as those involving multiple crossed and/or nested facets.

The execution of a reliability analysis from Generalizability Theory can be subdivided into two sequential steps. In the first part, known as the G-study, researchers use an ANOVA to estimate the variance components associated with all of the distinct sources of variation in the study design. From these components, the index of dependability, $\Phi$, can then be calculated for the G-study. $\Phi$ returns a value between 0 and 1 quantifying the degree to which the researcher could reliably generalize to the true score from a *single* observed score.

Most researchers, however, are more interested in the second step of the G-Theory process known as the D-study. The D-study (i.e. ‚ÄúDecision‚Äù study) permits the researcher to test out various numbers of trials, raters, occasions, etc. and determine the optimal number for reaching a particular reliability threshold. This is done by dividing the variance components from the G-study by the desired number of iterations for a given facet, then recalculating the index of dependability, ùöΩ. The interpretation of $\Phi$ then becomes the reliability with which the researcher can generalize to the true score by *averaging* over x number of trials or y number of raters, for example.

### Bayesian Statistics

Bayesian statistics is a branch of statistics based on Bayes' Theorem, which is a framework for updating our beliefs about a hypothesis, parameter, event, etc. when new information arises. The output obtained from a Bayesian analysis is a full "posterior" probability distribution, which serves as a compromise between our prior beliefs and the observed data.

This Bayesian framework is advantageous for a number of reasons. First, the ability to incorporate expert knowledge or historical data into the model as a prior distribution allows the researcher to eliminate any unnecessary uncertainty in the parameter estimates, which is especially useful in the context of small sample sizes and/or small effects. While this vignette opts to keep the default null priors in the sample analysis that follows, a separate vignette called "Setting-Priors" walks the user through the process of setting informative priors in `bayesian.gtheory`.

Additionally, the estimation of full probability distributions, rather than point estimates, permits us to make direct probability statements about the value(s) of interest, as well as construct 95% *credible* intervals for model parameters and predicted values. Not only does this make decision-making much more intuitive, but it also permits us to bypass certain assumptions in the construction of frequentist confidence intervals, such as the unrealistic assumption of multivariate normality.

### Putting It All Together: Bayesian G-Theory

When a reliability analysis from Generalizability Theory is executed through a Bayesian framework, the main difference lies in the way the results are displayed. Instead of receiving point estimates for each of the variance components, as well as the index of dependability, the user obtains summary statistics to encapsulate each posterior probability distribution. For both the variance components and the indices of dependability, the output contains a lower and upper bound on the value of interest (set as the 95% credible interval, by default) as well as the median of the distribution. The output of the D-study also displays the probability of $\Phi$ being above a certain user-inputted threshold (set to 0.7 by default).

Another main difference, as mentioned before, is the ability to set prior distributions for each of the variance components if the researcher is so inclined. An outline of this process is detailed in the "Setting-Priors" vignette, so do check that out if you are interested. Otherwise, keeping the default null priors, as we do in the following analysis, is standard protocol.

Finally, the user has the option to customize the settings of the Markov Chain Monte Carlo (MCMC) sampling method, which estimates the underlying probability distributions. In the `bayesian.gtheory` package, the user can alter the number of iterations per chain (both burn-in and total), the number of Markov chains, and the number of cores for parallel processing. Users also have the option of tuning two additional parameters called adapt_delta and max_treedepth to reduce the risk of divergent transitions in the sampling process. If the user is unfamiliar with MCMC sampling, the default settings will almost certainly suffice.

## Installing the Package and Its Dependencies

To install and load in the `bayesian.gtheory` package, simply run the following code:

```{r, eval = FALSE}
# install.packages("devtools")
devtools::install_github("t-clark04/bayesian.gtheory", dependencies = TRUE, build_vignettes = TRUE)
```

Before using the package, however, the `cmdstanr` package must also be properly installed in your RStudio. To do so, follow these instructions:

```{r, eval = FALSE}
# First, run this line of code.
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
# Then, run this line.
cmdstanr::install_cmdstan(). 
# Finally, verify successful installation with this line. 
cmdstanr::cmdstan_version().
```

Once you've completed these two steps, you're ready to go!

## Sample Analysis

Start by loading in the data from your study. Before you begin your analysis, make sure that your data frame contains a column for your outcome variable of interest (called scores in the documentation), a column for your subjects (or general objects of measurement), and one or more columns for facets (like raters, trials, occasion, etc.). Also, take note of the format of your study. Is it a one-facet or a two-facet design? Are any of your facets nested, or are they all crossed? These are important questions that will dictate which function in the `bayesian.gtheory` package you will ultimately use. I'll start by loading in my own mock dataset:

```{r}
Person <- c(rep(1, 6), rep(2,6), rep(3,6), rep(4,6), rep(5,6))
Item <- c(rep(c(1,2,3,4,5,6),5))
Occasion <- c(rep(c(1,1,1,2,2,2), 5))
Score <- c(19,17,20,18,18,20,15,15,17,16,17,17,20,20,19,20,20,
           20,11,14,12,12,13,12,18,19,18,19,18,19)
sample_data <- data.frame(Person, Item, Occasion, Score)
head(sample_data, 10)
```

As you can see, my `sample_data` data frame contains a column for my subjects (called "Person"), a column for my variable of interest (called "Score"), and two columns for facets (called "Item" and "Occasion", respectively). It is also important to note here that in this study, items are nested within occasions, and each of those item-occasion combinations is then crossed with persons. So, I have a p x (i:o) study design.

To see which of the functions in the package is suited for your study design, check the function dictionary displayed below. The table is also available in the README of the main GitHub repository as well (see <https://github.com/t-clark04/bayesian.gtheory>).

| Function Name      | Study Design      |
|--------------------|-------------------|
| dstudy_crossed1()  | *p* x *i*         |
| dstudy_crossed2()  | *p* x *i* x *o*   |
| dstudy_nested1()   | *i* : *p*         |
| dstudy_nested2()   | *i* : *o* : *p*   |
| dstudy_p_nested1() | (*i* : *p*) x *o* |
| dstudy_p_nested2() | *p* x (*i* : *o*) |
| dstudy_p_nested3() | *i* : (*p* x *o*) |
| dstudy_p_nested4() | (*i* x *o*) : *p* |

(Note: *p* represents the objects of measurement, and *i* and *o* are arbitrary facets.)

In the function dictionary, I see that my study design corresponds to the dstudy_p_nested2() function, so that's the function I'll be using to execute my Bayesian G- and D-studies.

To run the analysis, pass the data frame into the `data` parameter, then specify the column names (as strings!) for each of `col.scores`, `col.subjects`, `col.facet1`, and `col.facet2`. After that, enter two sequences of values to test out for facet1 and facet2 in the D-study through the `seq1` and `seq2` parameters. The rest of the function arguments can be kept as their default values, but for the sake of demonstration, I'll also set the probability threshold to 0.6 instead, and I'll bump up the total number of iterations in the MCMC chain to 6000 through the `iter` parameter. As mentioned earlier, the `prior` will remain `NULL` for this analysis, but head over to the "Setting-Priors" vignette for instructions on how to set prior distributions.

To obtain descriptions of all the parameters for your function of interest, simply pull up the help file by running `?your_function`. For instance, in my case, I would run `?dstudy_p_nested2` for more information.

One note to make when playing around with the function parameters is that the number of threads used for within-chain parallelization is set to 2 by default and cannot be changed. In general, the number of cores multiplied by the number of threads should not exceed the number of logical CPU cores in your operating system. Therefore, adjust the cores parameter accordingly! To check how many logical cores your operating system has, run `parallel::detectCores()` in the console.

Let's run the function and see what we get!

```{r, echo = TRUE, results = "hide", message = FALSE, warning = FALSE}
results <- dstudy_p_nested2(data = sample_data, col.scores = "Score", col.subjects = "Person", col.facet1 = "Item", col.facet2 = "Occasion", seq1 = seq(1,10,1), seq2 = seq(1,3,1), threshold = 0.6, iter = 6000)
```

```{r}
results$gstudy
```

```{r}
results$dstudy
```

As you can see, by utilizing a Bayesian framework, we can make direct probability statements and construct 95% credible intervals around both the variance components and the corresponding reliability coefficients. This gives the researcher a better idea of the uncertainty around their reliability metrics, thereby permitting them to make more informed decisions as a result.

### Notes

Thank you to Sven de Maeyer from the University of Antwerp for inspiring this Bayesian G-Theory package! See his blog post at <https://svendemaeyer.netlify.app/posts/2021-04-generalizability/>.

The median is used as the measure of center for both the variance components and the reliability coefficients because these distributions are rarely normal (or even symmetric). The most appropriate measure of center for skewed distributions like these is the one which is most resistant to outliers, which is the median.

Column names passed into the function must follow C++ naming conventions (i.e. only letters, numbers, or underscores; no spaces or hyphens!).
